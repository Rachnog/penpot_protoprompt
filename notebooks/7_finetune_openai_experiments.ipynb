{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image, SVG\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "from src.utils import *\n",
    "from src.svg_quality_checks import *\n",
    "from src.gpt_wrappers import *\n",
    "from src.langchain_database import *\n",
    "\n",
    "# show svg \n",
    "def show_svg(file):\n",
    "    display(SVG(file))\n",
    "\n",
    "# load yaml config\n",
    "with open(\"../config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import wandb\n",
    "\n",
    "openai.api_key = config[\"OPENAI_KEY\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an OpenAI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAIChat, OpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = create_sources_from_files(path = \"../training_data_raw/\", \n",
    "                                    description = \"SVG for\",\n",
    "                                    openai_document = False\n",
    "                                    )\n",
    "\n",
    "dataset = []\n",
    "for source in sources:\n",
    "    question = \\\n",
    "    \"\"\"Generate an SVG of {object_name} with the following style of {style}\"\"\".format(\n",
    "        object_name = source['source'].split(\"/\")[-1].split(\".\")[0],\n",
    "        style = source['source'].split(\"/\")[-2]\n",
    "    )\n",
    "    answer = source['svg']\n",
    "    dataset.append({\"prompt\": question, \"completion\": answer})\n",
    "\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate an SVG of input-text-disabled-lg with...</td>\n",
       "      <td>&lt;svg viewBox=\"0.00,0.00,320.00,40.00\"&gt;&lt;g&gt;&lt;rect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate an SVG of btn-danger-text-sm with the...</td>\n",
       "      <td>&lt;svg viewBox=\"0.00,0.00,104.00,24.00\"&gt;&lt;g&gt;&lt;rect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate an SVG of tootlip-top-right with the ...</td>\n",
       "      <td>&lt;svg viewBox=\"0.00,0.00,166.00,68.00\"&gt;&lt;defs&gt;&lt;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate an SVG of tooltip-left-middle with th...</td>\n",
       "      <td>&lt;svg viewBox=\"0.00,0.00,171.00,63.00\"&gt;&lt;defs&gt;&lt;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate an SVG of input-text-hover with the f...</td>\n",
       "      <td>&lt;svg viewBox=\"0.00,0.00,320.00,32.00\"&gt;&lt;g&gt;&lt;rect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Generate an SVG of Icon_Button_Filled_[Disable...</td>\n",
       "      <td>&lt;svg fill=\"none\" viewBox=\"0.00,0.00,48.00,48.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Generate an SVG of Elevated_Filter_Chip_Off_[d...</td>\n",
       "      <td>&lt;svg fill=\"none\" viewBox=\"0.00,0.00,121.00,32....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Generate an SVG of Avatar_Small_[disabled] wit...</td>\n",
       "      <td>&lt;svg fill=\"none\" viewBox=\"0.00,0.00,24.00,24.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>Generate an SVG of 3_Lines_Video_List_+_Contro...</td>\n",
       "      <td>&lt;svg fill=\"none\" viewBox=\"0.00,0.00,360.00,88....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Generate an SVG of Assist_Chip_+_Icon with the...</td>\n",
       "      <td>&lt;svg fill=\"none\" viewBox=\"0.00,0.00,146.00,32....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    Generate an SVG of input-text-disabled-lg with...   \n",
       "1    Generate an SVG of btn-danger-text-sm with the...   \n",
       "2    Generate an SVG of tootlip-top-right with the ...   \n",
       "3    Generate an SVG of tooltip-left-middle with th...   \n",
       "4    Generate an SVG of input-text-hover with the f...   \n",
       "..                                                 ...   \n",
       "655  Generate an SVG of Icon_Button_Filled_[Disable...   \n",
       "656  Generate an SVG of Elevated_Filter_Chip_Off_[d...   \n",
       "657  Generate an SVG of Avatar_Small_[disabled] wit...   \n",
       "658  Generate an SVG of 3_Lines_Video_List_+_Contro...   \n",
       "659  Generate an SVG of Assist_Chip_+_Icon with the...   \n",
       "\n",
       "                                            completion  \n",
       "0    <svg viewBox=\"0.00,0.00,320.00,40.00\"><g><rect...  \n",
       "1    <svg viewBox=\"0.00,0.00,104.00,24.00\"><g><rect...  \n",
       "2    <svg viewBox=\"0.00,0.00,166.00,68.00\"><defs><f...  \n",
       "3    <svg viewBox=\"0.00,0.00,171.00,63.00\"><defs><f...  \n",
       "4    <svg viewBox=\"0.00,0.00,320.00,32.00\"><g><rect...  \n",
       "..                                                 ...  \n",
       "655  <svg fill=\"none\" viewBox=\"0.00,0.00,48.00,48.0...  \n",
       "656  <svg fill=\"none\" viewBox=\"0.00,0.00,121.00,32....  \n",
       "657  <svg fill=\"none\" viewBox=\"0.00,0.00,24.00,24.0...  \n",
       "658  <svg fill=\"none\" viewBox=\"0.00,0.00,360.00,88....  \n",
       "659  <svg fill=\"none\" viewBox=\"0.00,0.00,146.00,32....  \n",
       "\n",
       "[660 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"../data/dataset.jsonl\"\n",
    "dataset.to_json(DATASET_FILE, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 660 prompt-completion pairs\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- All prompts start with prefix `Generate an SVG of `. Fine-tuning doesn't require the instruction specifying the task, or a few-shot example scenario. Most of the time you should only add the input data into the prompt, and the desired output into the completion\n",
      "- All completions start with prefix `<svg `. Most of the time you should only add the output data into the completion, without any prefix\n",
      "- All completions end with suffix `></g></svg>`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
      "- [Recommended] Remove prefix `Generate an SVG of ` from all prompts [Y/n]: Y\n",
      "- [Recommended] Remove prefix `<svg ` from all completions [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `../data/dataset_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../data/dataset_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"></g></svg>\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 11.51 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f ../data/dataset.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-xC7FHjj0O0pf6JBejDZSifJk at 0x1583f8270> JSON: {\n",
       "  \"bytes\": 1228254,\n",
       "  \"created_at\": 1681988250,\n",
       "  \"filename\": \"file\",\n",
       "  \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_response = openai.File.create(\n",
    "  file=open(DATASET_FILE, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_id = upload_response.id\n",
    "upload_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject fine-tune-event at 0x1585aaf40> JSON: {\n",
       "   \"created_at\": 1681988844,\n",
       "   \"level\": \"info\",\n",
       "   \"message\": \"Created fine-tune: ft-6XOvgdZneEGlBPzhJNsXSH7V\",\n",
       "   \"object\": \"fine-tune-event\"\n",
       " }]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_response = openai.FineTune.create(\n",
    "    training_file=upload_response['id']\n",
    "    ) # openai.FineTune.create(training_file=upload_response['id'], model=\"davinci\")\n",
    "fine_tune_response.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created_at\": 1681988279,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-ZBtyAGGRZgpM8LInVRJ9xHZk\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"cancelled\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988673,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1681988351,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-UidLDkLiPfIkWU9jrGjVILqq\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"cancelled\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988730,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1681988368,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-qC50tTmgQsHmJMBgu73EtHi7\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"cancelled\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988739,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1681988404,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-K4shQzKghkKoS4xwgRsyeV9H\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"cancelled\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988753,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1681988484,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-2TlCgMSn6p9ZqaJ2WXoTCoa4\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"cancelled\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988764,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1681988485,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-d8WD7S8m6KOQvANHEad2Zp3m\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"cancelled\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988773,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1681988844,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": null,\n",
      "        \"learning_rate_multiplier\": null,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-6XOvgdZneEGlBPzhJNsXSH7V\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-4whisRJIhIJtFAsnpmbxhLSC\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"pending\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 1228254,\n",
      "          \"created_at\": 1681988250,\n",
      "          \"filename\": \"file\",\n",
      "          \"id\": \"file-xC7FHjj0O0pf6JBejDZSifJk\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1681988844,\n",
      "      \"validation_files\": []\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! openai api fine_tunes.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
